{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-venv-pda_nexus",
      "display_name": "Python (env PDA_NEXUS)",
      "language": "python"
    },
    "associatedRecipe": "compute_PDA_TEST_PROJECT_METADATA",
    "dkuGit": {
      "lastInteraction": 0
    },
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "gopina02"
      },
      "lastModifiedOn": 1641368713274
    },
    "creator": "gopina02",
    "createdOn": 1641368713274,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {},
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.6.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "gopina02"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\nimport dataiku\nimport pandas as pd, numpy as np\nfrom dataiku import pandasutils as pdu\nfrom dataiku.core.sql import SQLExecutor2\n\n# Read recipe inputs\npda_MV_PROJECT_MASTER \u003d dataiku.Dataset(\"PDA_MV_PROJECT_MASTER\")\npda_MV_PROJECT_MASTER_df \u003d pda_MV_PROJECT_MASTER.get_dataframe()\npda_STG_ENRICH_PROJECT_METADATA_BASE_QUERY \u003d dataiku.Dataset(\"PDA_STG_ENRICH_PROJECT_METADATA_BASE_QUERY\")\npda_STG_ENRICH_PROJECT_METADATA_BASE_QUERY_df \u003d pda_STG_ENRICH_PROJECT_METADATA_BASE_QUERY.get_dataframe()\n\nPDA_TEST_PROJECT_METADATA \u003d dataiku.Dataset(\"PDA_TEST_PROJECT_METADATA\")\nPDA_TEST_PROJECT_METADATA_df \u003d PDA_TEST_PROJECT_METADATA.get_dataframe()\n# PDA_TEST_PROJECT_METADATA_df"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pda_MV_PROJECT_MASTER_df"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "client \u003d dataiku.api_client()\nDSSProject \u003d client.get_project(\"PDANEXUSANALYTICS\")\nvariables \u003d DSSProject.get_variables()\nvariables[\"standard\"][\"Project_Metadata_New_Columns\"]\u003d \u0027\u0027\nDSSProject.set_variables(variables)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# merge enrich data with project master data\nPDA_MV_PROJECT_METADATA_df \u003d pd.merge(pda_STG_ENRICH_PROJECT_METADATA_BASE_QUERY_df,pda_MV_PROJECT_MASTER_df, on\u003d\u0027CANDIDATE_CODE\u0027,  how\u003d\u0027left\u0027, suffixes\u003d(\u0027\u0027, \u0027_DROP\u0027)).filter(regex\u003d\u0027^(?!.*_DROP)\u0027)\nPDA_MV_PROJECT_METADATA_df[\u0027Dummy111\u0027] \u003d\u0027Dummy\u0027\nPDA_MV_PROJECT_METADATA_df[\u0027Dummy114\u0027] \u003d\u0027Dummy\u0027\nPDA_MV_PROJECT_METADATA_df[\u0027Dummy11\u0027] \u003d\u0027Dummy\u0027\nPDA_MV_PROJECT_METADATA_df[\u0027Dummy113\u0027] \u003d\u0027Dummy\u0027\nPDA_MV_PROJECT_METADATA_df[\u0027Dummy1131\u0027] \u003d\u0027Dummy\u0027"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "PDA_MV_PROJECT_METADATA_df[\u0027CANDIDATE_PRIMARY_FORMULATION\u0027]\u003d PDA_MV_PROJECT_METADATA_df[\u0027CANDIDATE_PRIMARY_FORMULATION\u0027].astype(float)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def load_to_partition(df, partition_table,partitioned_on, writeWithSchema \u003d False):\n    #Group dataframe for easy partitioning\n    partition_table_dataset \u003d dataiku.Dataset(partition_table)\n    GROUPED_df \u003d df.groupby([partitioned_on])\n    try:\n        for key, TMP_PORTFOLIO_df in GROUPED_df:\n            partition_table_dataset.set_write_partition(key)\n#             #print(\u0027Writing Portfolio: \u0027, str(int(key)), \u0027 Rows: \u0027, str(len(TMP_PORTFOLIO_df.index)))\n#     #         logging.info(\u0027***********Writing to \u0027 + partition_table +\u0027: \u0027 +  str(int(key)) + \u0027 Rows: \u0027 + str(len(TMP_PORTFOLIO_df.index)) )\n\n            if writeWithSchema:\n                partition_table_dataset.write_schema_from_dataframe(df)\n\n            partition_table_dataset.write_from_dataframe(TMP_PORTFOLIO_df)\n        return \u0027Success\u0027\n    except Exception as e:\n        return \u0027Failed\u0027\n\n# Load_Status \u003d load_to_partition(PDA_MV_PROJECT_METADATA_df, \"PDA_TEST_PROJECT_METADATA\",\u0027PORTFOLIO_ID\u0027, True)\n\n# if Load_Status \u003d\u003d \u0027Success\u0027:\n#     pass\n# elif Load_Status \u003d\u003d \u0027Failed\u0027:\n#     print(\u0027fail\u0027)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def gen_load_alter_cols(df):\n    # print(PDA_MV_PROJECT_METADATA_df.dtypes)\n    col_names \u003d df.dtypes.keys().to_list()\n    col_dtypes \u003d list(df.dtypes.values)\n\n    map_dtype \u003d [(\"float64\",\"double\"), (\"object\",\"string\"), (\"int64\",\"int\")]\n\n    new_datatype \u003d []\n    for ele in col_dtypes:\n        for ele1 in map_dtype:\n            if ele \u003d\u003d ele1[0]:\n                new_datatype.append(ele1[1])\n\n    col_dtype \u003d dict(zip(col_names,new_datatype))\n    list_of_new_cols_dtypes \u003d []\n    for key, value in col_dtype.items():\n        a \u003d key + \u0027 \u0027 + value\n        list_of_new_cols_dtypes.append(a)\n\n    alter_table_cols \u003d np.array(list_of_new_cols_dtypes, str)\n    joined_string \u003d    \",\".join([str for str in alter_table_cols])\n\n    sqlVar \u003d  joined_string\n\n    variables[\"standard\"][\"Project_Metadata_New_Columns\"] \u003d sqlVar\n    DSSProject.set_variables(variables)\n    return \u0027loaded the alter table list of columns to global variable: Project_Metadata_New_Columns\u0027\n\n# alter_col_list \u003d gen_load_alter_cols(only_df)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def missing_cols(df1,df2):\n    df1_list \u003d [x.upper() for x in list(df1)]\n    df2_list \u003d [x.upper() for x in list(df2)]\n    if df1_list \u003d\u003d df2_list:\n        print(\"Both Datasets are Identical\")\n        print(df1[\u0027CANDIDATE_PRIMARY_FORMULATION\u0027].dtype)\n        Load_Status \u003d load_to_partition(df1, \"PDA_TEST_PROJECT_METADATA\",\u0027PORTFOLIO_ID\u0027, True)\n        return \u0027Loading data into partition Table: \u0027 + Load_Status\n    elif len(df1_list) \u003e len(df2_list):\n        print(df1_list)\n        print(df2_list)\n        final_list \u003d list((set(df1_list).difference(df2_list)))\n        print(\u0027Additional Columns in PDA_MV_PROJECT_METADATA_df:\u0027,final_list)\n        Load_Status \u003d gen_load_alter_cols(df1[final_list])\n        return Load_Status\n    elif len(df1_list) \u003c len(df2_list):\n        final_list \u003d list((set(df2_list).difference(df1_list)))\n        print(\u0027Additional Columns in PDA_TEST_PROJECT_METADATA:\u0027,final_list)\n        print(df1[\u0027CANDIDATE_PRIMARY_FORMULATION\u0027].dtype)\n        for col in final_list:\n            df1[col] \u003d \u0027\u0027\n        df1\u003ddf1[df2.columns]\n        Load_Status \u003d load_to_partition(df1, \"PDA_TEST_PROJECT_METADATA\",\u0027PORTFOLIO_ID\u0027, True)\n        return \u0027Loading data into partition Table: \u0027 + Load_Status"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "new_cols_list \u003d missing_cols(PDA_MV_PROJECT_METADATA_df,PDA_TEST_PROJECT_METADATA_df)\nnew_cols_list"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "user \u003d dataiku.get_custom_variables()[\u0027ENRICH_PORTFOLIO_IDS_TO_INCLUDE\u0027]\nuser"
      ],
      "outputs": []
    }
  ]
}