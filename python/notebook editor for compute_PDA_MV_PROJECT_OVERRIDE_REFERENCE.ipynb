{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-venv-pda_nexus",
      "display_name": "Python (env PDA_NEXUS)",
      "language": "python"
    },
    "associatedRecipe": "compute_PDA_MV_PROJECT_OVERRIDE_REFERENCE",
    "dkuGit": {
      "lastInteraction": 0
    },
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "gopina02"
      },
      "lastModifiedOn": 1638380123362
    },
    "creator": "gopina02",
    "createdOn": 1638380123362,
    "tags": [],
    "customFields": {},
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.6.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "gopina02"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\nimport dataiku\nimport pandas as pd, numpy as np\nfrom dataiku import pandasutils as pdu\nimport functools\nimport json\nfrom multiprocessing import Pool\n\n# importing functions from project libraries\nfrom SharePointFunctions import read_SPList\nfrom OVERRIDE_FUNCTIONS import override_dataframe"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PROJECT METADATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reading OneSource and OneSource Enrich Snowflake Tables"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Read recipe inputs\nPDA_STG_PROJECT_REFERENCE_OS_PORTFOLIO \u003d dataiku.Dataset(\"PDA_STG_PROJECT_REFERENCE_OS_PORTFOLIO\")\nPDA_STG_PROJECT_REFERENCE_OS_PORTFOLIO_df \u003d PDA_STG_PROJECT_REFERENCE_OS_PORTFOLIO.get_dataframe()\n\nPDA_STG_PROJECT_REFERENCE_ENRICH \u003d dataiku.Dataset(\"PDA_STG_PROJECT_REFERENCE_ENRICH\")\nPDA_STG_PROJECT_REFERENCE_ENRICH_df \u003d PDA_STG_PROJECT_REFERENCE_ENRICH.get_dataframe()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reading Slipstream Snowflake tables for Overrides"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Read recipe inputs from snowflake\nPDA_MASTER_OVERRIDE_LIST \u003d dataiku.Dataset(\"PDA_SLIPSTREAM_MASTER_OVERRIDE_LIST\")\nPDA_MASTER_OVERRIDE_LIST_SF_df \u003d PDA_MASTER_OVERRIDE_LIST.get_dataframe()\n\nPDA_PROJECT_OVERRIDE_RULES \u003d dataiku.Dataset(\"PDA_SLIPSTREAM_PROJECT_OVERRIDE_RULES\")\nPDA_PROJECT_OVERRIDE_RULES_SF_df \u003d PDA_PROJECT_OVERRIDE_RULES.get_dataframe()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Applying Override Rules to Override Data with OneSource data"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# reading Snowflake tables for override table and override rules\nrules_df \u003d PDA_PROJECT_OVERRIDE_RULES_SF_df.copy()\ntarget_df \u003d PDA_STG_PROJECT_REFERENCE_OS_PORTFOLIO_df.copy()\noverride_df \u003d PDA_MASTER_OVERRIDE_LIST_SF_df.copy()\n#target_df"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "OS_PORTFOLIO_OVERRIDDEN_df \u003d override_dataframe(rules_df, target_df, override_df)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Merge OneSource override data with OneSource Enrich Data"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# function to merge OneSource override data with OneSource Enrich Data\ndef merge_os_df(LEFT_DF, RIGHT_DF, key\u003d\u0027CANDIDATE_CODE\u0027):\n    try:\n        # Finding Common columns\n        common_cols \u003d list(np.intersect1d(LEFT_DF.columns, RIGHT_DF.columns))\n        common_cols.remove(key)\n\n        # for each common column in left df it fills na values from right df  and finally merges two dfs(needs to confirm)\n        for col in common_cols:\n            LEFT_DF[col].fillna(RIGHT_DF[col])\n            RIGHT_DF \u003d RIGHT_DF.drop(col,axis\u003d1)\n        DF \u003d pd.merge(LEFT_DF,RIGHT_DF,on\u003dkey,  how\u003d\u0027left\u0027)\n\n        # sorts the columns alphabetically\n        DF \u003d DF.reindex(sorted(DF.columns), axis\u003d1)\n\n        #move the PROJECT_ID column to first of the dataframe\n        starting_cols \u003d [\u0027PROJECT_ID\u0027,\u0027PORTFOLIO_ID\u0027,key]\n        DF \u003d DF[ starting_cols + [ col for col in DF.columns if col not in starting_cols] ]\n        DF[[\u0027PROJECT_ID\u0027,\u0027PORTFOLIO_ID\u0027]] \u003d DF[[\u0027PROJECT_ID\u0027,\u0027PORTFOLIO_ID\u0027]].astype(int)\n\n        return DF\n    except Exception as e:\n        print(\u0027merge_os_df failed, error:\u0027, str(e))\n        pass"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# calling the function to merge data based on condition\nLEFT_DF \u003d PDA_STG_PROJECT_REFERENCE_ENRICH_df.copy()\nRIGHT_DF \u003d OS_PORTFOLIO_OVERRIDDEN_df.copy()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "PDA_MV_PROJECT_METADATA_df \u003d merge_os_df(LEFT_DF, RIGHT_DF)\n# PDA_MV_PROJECT_METADATA_df"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Writing to output"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# PDA_STG_MV_PROJECT_METADATA \u003d dataiku.Dataset(\"PDA_STG_MV_PROJECT_METADATA\")\n# PDA_STG_MV_PROJECT_METADATA.write_with_schema(PDA_MV_PROJECT_METADATA_df)\n\n# PDA_STG_MV_PROJECT_MASTER \u003d dataiku.Dataset(\"PDA_STG_MV_PROJECT_MASTER\")\n# PDA_STG_MV_PROJECT_MASTER.write_with_schema(OS_PORTFOLIO_OVERRIDDEN_df)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PORTFOLIO METADATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reading Input Data"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "PDA_STG_ENRICH_PORTFOLIO_METADATA \u003d dataiku.Dataset(\"PDA_STG_ENRICH_PORTFOLIO_METADATA\")\nPDA_STG_ENRICH_PORTFOLIO_METADATA_df \u003d PDA_STG_ENRICH_PORTFOLIO_METADATA.get_dataframe()\n\nPDA_SLIPSTREAM_PORTFOLIO_ATTRIBUTES \u003d dataiku.Dataset(\"PDA_SLIPSTREAM_PORTFOLIO_ATTRIBUTES\")\nPDA_SLIPSTREAM_PORTFOLIO_ATTRIBUTES_df \u003d PDA_SLIPSTREAM_PORTFOLIO_ATTRIBUTES.get_dataframe()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Processing"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# merging data\nPDA_STG_ENRICH_PORTFOLIO_METADATA_MERGED_df \u003d PDA_STG_ENRICH_PORTFOLIO_METADATA_df.merge(PDA_SLIPSTREAM_PORTFOLIO_ATTRIBUTES_df,\n             how\u003d\u0027left\u0027, on\u003d[\"PORTFOLIO_ID\"] ,suffixes\u003d(\u0027_DROPME\u0027, \u0027\u0027)).filter(regex\u003d\u0027^(?!.*_DROPME)\u0027)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Write recipe outputs"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# deleteme_Portfolio_Metadata \u003d dataiku.Dataset(\"PDA_TEST_MV_PORTFOLIO_METADATA\")\n# deleteme_Portfolio_Metadata.write_with_schema(PDA_STG_ENRICH_PORTFOLIO_METADATA_MERGED_df)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OUTPUT TIMESERIES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reading Input Data"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "PDA_OUTPUT_TIMESERIES_TYPES_df \u003d dataiku.Dataset(\"PDA_SLIPSTREAM_TIMESERIES_TYPES\")\nPDA_OUTPUT_TIMESERIES_TYPES_df \u003d PDA_OUTPUT_TIMESERIES_TYPES_df.get_dataframe()\n\n#Replacing OS Global and Regional PNLs with Unioned snowflake PNL (pre-filtered by Portfolio ID)\nPDA_STG_ENRICH_PNL \u003d dataiku.Dataset(\"PDA_STG_ENRICH_PNL\")\nPDA_STG_ENRICH_PNL_df \u003d PDA_STG_ENRICH_PNL.get_dataframe()\n\n#Adding Dev Costs - this is a bit of a force fit may need to run as a separate table, depending on how captario structures\nPDA_STG_ENRICH_DC \u003d dataiku.Dataset(\"PDA_STG_ENRICH_DC\")\nPDA_STG_ENRICH_DC_df \u003d PDA_STG_ENRICH_DC.get_dataframe()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Processing"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Sharepoint Derived listing to edit see:\n# https://pfizer.sharepoint.com/sites/PDADATASETS/CORE/Lists/PDA_OUTPUT_TIMESERIES_TYPES\n#list includes both PNL and Dev Cost elements, Implicit assumption there is no naming overlap between these entities\nSYSTEM_TIMESERIES_list \u003d PDA_OUTPUT_TIMESERIES_TYPES_df[\u0027SYSTEM_TIMESERIES\u0027].tolist()\nSYSTEM_TIMESERIES_list \u003d list(set(SYSTEM_TIMESERIES_list))\n\n#creating specific list relevant to PNL, unpivot operation will fail if given invalid column references\nSYSTEM_TIMESERIES_PNL_list \u003d  list(set(SYSTEM_TIMESERIES_list) \u0026 set(PDA_STG_ENRICH_PNL_df.columns.values.tolist()))\n\n\n# Unpivot PNL Data\nPDA_STG_ENRICH_PNL_FILTERED_NORMALIZED_df \u003d pd.melt(PDA_STG_ENRICH_PNL_df,\n                                             id_vars\u003d[\u0027PORTFOLIO_ID\u0027, \u0027PROJECT_ID\u0027, \u0027SNAPSHOT_ID\u0027,\u0027CANDIDATE_CODE\u0027,\n                                                      \u0027SOURCE\u0027,\u0027COMPONENT\u0027, \u0027REGION\u0027,\u0027YEAR\u0027,\u0027SCENARIO\u0027,\u0027PHASE\u0027],\n                                             value_vars\u003d SYSTEM_TIMESERIES_PNL_list,\n                                              var_name\u003d\u0027TYPE\u0027, value_name\u003d\u0027VALUE\u0027)\n\n#Union PNL And Dev costs\nPDA_STG_CONCAT_PNL_DC_df \u003d pd.concat([PDA_STG_ENRICH_PNL_FILTERED_NORMALIZED_df,PDA_STG_ENRICH_DC_df])"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Write recipe outputs"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# PDA_MV_OUTPUT_TIMESERIES \u003d dataiku.Dataset(\"PDA_STG_MV_OUTPUT_TIMESERIES\")\n# PDA_MV_OUTPUT_TIMESERIES.write_with_schema(PDA_STG_CONCAT_PNL_DC_df)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OUTPUT VALUES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reading Input Data"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "PDA_SLIPSTREAM_PORTFOLIO_ATTRIBUTES \u003d dataiku.Dataset(\"PDA_SLIPSTREAM_PORTFOLIO_ATTRIBUTES\")\nPDA_SLIPSTREAM_PORTFOLIO_ATTRIBUTES_df \u003d PDA_SLIPSTREAM_PORTFOLIO_ATTRIBUTES.get_dataframe()\n\nPDA_SLIPSTREAM_VALUE_TYPES \u003d dataiku.Dataset(\"PDA_SLIPSTREAM_VALUE_TYPES\")\nPDA_SLIPSTREAM_VALUE_TYPES_df \u003d PDA_SLIPSTREAM_VALUE_TYPES.get_dataframe()\n\nPDA_STG_ENRICH_FLATFILE \u003d dataiku.Dataset(\"PDA_STG_ENRICH_FLATFILE\")\nPDA_STG_ENRICH_FLATFILE_df \u003d PDA_STG_ENRICH_FLATFILE.get_dataframe()\n\nPDA_STG_ENRICH_DC \u003d dataiku.Dataset(\"PDA_STG_ENRICH_DC\")\nPDA_STG_ENRICH_DC_df \u003d PDA_STG_ENRICH_DC.get_dataframe()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Processing"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "FF_ECONOMICS_df \u003d  pd.merge( PDA_SLIPSTREAM_VALUE_TYPES_df, PDA_STG_ENRICH_FLATFILE_df, how\u003d\u0027inner\u0027, left_on\u003d\u0027SYSTEM_VALUES\u0027, right_on\u003d\u0027COLUMN_NAME\u0027)[[\u0027PORTFOLIO_ID\u0027,\u0027PROJECT_ID\u0027,\u0027SNAPSHOT_ID\u0027,\u0027CANDIDATE_CODE\u0027,\u0027COLUMN_NAME\u0027, \u0027COLUMN_DATA\u0027]]\nFF_ECONOMICS_df.rename(columns\u003d{\u0027COLUMN_NAME\u0027: \u0027TYPE\u0027, \u0027COLUMN_DATA\u0027: \u0027VALUE\u0027}, inplace\u003dTrue)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Write recipe outputs"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# PDA_TMP_MV_OUTPUT_VALUES \u003d dataiku.Dataset(\"PDA_STG_MV_OUTPUT_VALUES\")\n# PDA_TMP_MV_OUTPUT_VALUES.write_with_schema(FF_ECONOMICS_df)"
      ],
      "outputs": []
    }
  ]
}